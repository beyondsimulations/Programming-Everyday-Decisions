---
title: "Lecture V - Randomness"
subtitle: "Programming: Everyday Decision-Making Algorithms"
author: "Dr. Tobias Vlćek"
institute: "Kühne Logistics University Hamburg - Winter 2024"
title-slide-attributes:
    data-background-color: "#8C3048"

format:
    revealjs:
        theme: [default, ../styles.scss]
        transition: slide
        transition-speed: fast
        highlight-style: arrow
        code-overflow: wrap
        slide-number: true
        code-copy: true
        code-link: true
        preview-links: auto
        footer: " {{< meta title >}} | {{< meta author >}} | [Home](lecture-scheduling.qmd)"
        output-file: lecture-presentation.html
        mermaid:
            theme: neutral

    html:
        theme: litera
        mermaid:
            theme: neutral

execute:
    eval: true

---

# [Understanding Randomness]{.flow} {.title}

## Randomness

[Question:]{.question} **What comes to your mind when you think of randomness?**

. . .

- **Dice rolls** that are uniformly distributed
- **Coin flips** with a binary outcome
- **Lottery numbers** based on a random draw
- **Shuffling cards** in a deck
- **Genetic mutations** in biology

## Why Randomness Matters

[Question:]{.question} **What's the opposite of randomness?**

. . .

- **Determinism**
- **Predictability**
- **Consistency**

. . .

- [Boredom?]{.highlight}

## Discovery by Randomness

[Question:]{.question} **How would you test if a pair of dice is fair?**

. . .

- Send the dice **to a lab** to [check weight and balance]{.highlight}

. . .

- Roll the dice **many times**
- Check if the outcomes are **uniformly distributed**
- Compare **observed** frequencies to **expected** frequencies

## Dice Rolls


```{python}
#| echo: false
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import pathlib

DIR = pathlib.Path(".").resolve()

# Setup the figure
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8), dpi=150)
plt.style.use('fivethirtyeight')

# Setup first subplot for rolling history
ax1.set_xlim(0, 200)
ax1.set_ylim(0.5, 6.5)
ax1.set_title('Dice Roll History')
ax1.set_xlabel('Roll Number')
ax1.set_ylabel('Roll Value')
ax1.grid(True, alpha=0.3)

# Setup second subplot for distribution
x = np.arange(1, 7)
expected_prob = [1/6] * 6  # Fair die probabilities
biased_prob = [0.1, 0.1, 0.1, 0.1, 0.1, 0.5]  # Biased die probabilities
ax2.set_xlim(0.5, 6.5)
ax2.set_ylim(0, 0.6)
ax2.set_title('Distribution of Outcomes')
ax2.set_xlabel('Roll Value')
ax2.set_ylabel('Probability')
ax2.grid(True, alpha=0.3)

# Plot expected probability lines
ax2.plot(x, expected_prob, 'g--', label='Fair Die (Expected)', alpha=0.7)
ax2.plot(x, biased_prob, 'r--', label='Biased Die (Expected)', alpha=0.7)
ax2.legend()

# Initialize data
fair_rolls = []
biased_rolls = []
fair_line, = ax1.plot([], [], 'g-', alpha=0.5, label='Fair Die')
biased_line, = ax1.plot([], [], 'r-', alpha=0.5, label='Biased Die')
fair_scatter = ax1.scatter([], [], c='green', alpha=0.6)
biased_scatter = ax1.scatter([], [], c='red', alpha=0.6)
fair_bars = ax2.bar(x - 0.2, np.zeros_like(x), width=0.4, alpha=0.5, color='green', label='Fair Die (Observed)')
biased_bars = ax2.bar(x + 0.2, np.zeros_like(x), width=0.4, alpha=0.5, color='red', label='Biased Die (Observed)')

ax1.legend()
ax2.legend()

def biased_roll():
    # Returns 6 with 50% probability, others equally likely
    return np.random.choice(range(1, 7), p=biased_prob)

def update(frame):
    # Generate new rolls
    fair_roll = np.random.randint(1, 7)
    unfair_roll = biased_roll()
    
    fair_rolls.append(fair_roll)
    biased_rolls.append(unfair_roll)
    
    # Update rolling history
    fair_line.set_data(range(len(fair_rolls)), fair_rolls)
    biased_line.set_data(range(len(biased_rolls)), biased_rolls)
    fair_scatter.set_offsets(np.c_[range(len(fair_rolls)), fair_rolls])
    biased_scatter.set_offsets(np.c_[range(len(biased_rolls)), biased_rolls])
    
    # Update distributions
    if fair_rolls:
        fair_counts = np.bincount(fair_rolls)[1:]
        fair_probs = fair_counts / len(fair_rolls)
        biased_counts = np.bincount(biased_rolls)[1:]
        biased_probs = biased_counts / len(biased_rolls)
        
        for bar, prob in zip(fair_bars, fair_probs):
            bar.set_height(prob)
        for bar, prob in zip(biased_bars, biased_probs):
            bar.set_height(prob)
    
    return (fair_line, biased_line, fair_scatter, biased_scatter, *fair_bars, *biased_bars)

# Create and save animation
anim = FuncAnimation(fig, update, frames=200, interval=50, blit=True)
anim.save(DIR / 'dice_fairness.gif', writer='pillow')
plt.close()
```

![](dice_fairness.gif)

## Using Randomness

- Randomness is a [fundamental aspect of the world]{.highlight}
- Randomness is used to model **uncertainty**
- It is used to **explore** solutions and **avoid bias**

. . .

::: {.callout-important}
Randomness is not just about **generating random numbers**!
:::

# [Computational Applications]{.flow} {.title}

## Randomness and Everyday Life

[Question:]{.question} **Where do you see algorithms that use randomness in daily life?**

## Cryptography
- Bitcoin miners are playing a **giant random number lottery**
- Your password generator **not just generating random keys!**
- `correct-horse-battery-staple` is secure 
- `Tr0ub4dor&3` is not that secure
- [Encryption]{.highlight} uses randomness to create **uncrackable** keys

## Entertainment Industry

- Pokémon's "random" encounters are **carefully weighted**
- **Loot systems:** Better items have lower drop rates
- Chess AI makes **suboptimal moves** to be unpredictable
- Spotify shuffle makes it **less random to feel more random**

## Real-World Applications

- [Weather forecasting]{.highlight} uses random simulations
- **Stock algorithms** add randomness to avoid predictability
- **Self-driving cars** add randomness for natural behavior

. . .

::: {.callout-note}
Thus, we see that randomness is **everywhere** but also **not just about generating random numbers**!
:::

## Types of Randomness

[Question:]{.question} **What's the difference between true and pseudo-randomness?**

. . .

::: {.columns}
::: {.column width="50%"}
[True Randomness]{.highlight}

- Physical phenomena
- Atmospheric noise
- Radioactive decay
- Quantum effects
:::

::: {.column width="50%"}
[Pseudo-randomness]{.highlight}

- Deterministic algorithms
- Seed-based generation
- Repeatable sequences
- Good enough for most uses
:::
:::

## Randomness in Computer Science

- **Fundamental concept** in computer science
- Helps solve "hard" problems **efficiently**
- Often **faster than deterministic approaches**
- [Trade-off:]{.highlight} Optimal vs. "Good Enough" solutions

. . .

::: {.callout-important}
Sometimes a quick "good enough" solution is better than waiting for the perfect one.
:::

## Limits of Computation

[Question:]{.question} **How many possible combinations exist in a shuffled deck of cards?**

```{python}
#| echo: true
#| eval: true
#| output-location: fragment
import math
print(math.factorial(52))
```

. . .

::: {.callout-important}
Computing and evaluating all possible combinations is not feasible!
:::


## Addressing Computational Limits

[Question:]{.question} **Has anybody heard the term Monte Carlo methods?**

. . .

- Developed in the **1940s for nuclear weapons research**
- Nuclear fission chain reactions **were too complex**
- Helped to [evaluate the probabilities of different outcomes]{.highlight}
- Named after **Monaco's famous casino**

. . .

[Question:]{.question} **How could we estimate π?**

## Estimating π

```{python}
#| echo: false
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
import pathlib

DIR = pathlib.Path(".").resolve()

# Setup
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8), dpi=150) 

# Draw circle and square boundaries
circle = plt.Circle((0, 0), 1, fill=False, color='black')
ax1.add_artist(circle)
ax1.set_xlim(-1.1, 1.1)
ax1.set_ylim(-1.1, 1.1)
ax1.set_aspect('equal')
ax1.grid(True)
ax1.set_title('Monte Carlo Simulation')

# Setup pi estimation plot
ax2.set_xlim(0, 200)  # Reduced number of frames
ax2.set_ylim(2.8, 3.4)
ax2.axhline(y=np.pi, color='r', linestyle='--', label='π')
ax2.grid(True)
ax2.set_title('π Estimation')
ax2.legend()

# Pre-allocate points and create scatter plots once
points_per_frame = 10  # Process multiple points per frame
scatter_inside = ax1.scatter([], [], c='blue', alpha=0.6, s=20)
scatter_outside = ax1.scatter([], [], c='red', alpha=0.6, s=20)
line_estimate, = ax2.plot([], [], 'g-', alpha=0.5)

# Initialize arrays
inside_points = np.empty((0, 2))
outside_points = np.empty((0, 2))
estimates = np.empty(0)

def update(frame):
    global inside_points, outside_points, estimates
    
    # Generate batch of points
    points = np.random.uniform(-1, 1, (points_per_frame, 2))
    distances = np.sum(points**2, axis=1)
    
    # Split into inside/outside points
    new_inside = points[distances <= 1]
    new_outside = points[distances > 1]
    
    # Update arrays
    inside_points = np.vstack([inside_points, new_inside])
    outside_points = np.vstack([outside_points, new_outside])
    
    # Update scatter plots
    scatter_inside.set_offsets(inside_points)
    scatter_outside.set_offsets(outside_points)
    
    # Calculate and update pi estimation
    total_points = len(inside_points) + len(outside_points)
    if total_points > 0:
        pi_estimate = 4 * len(inside_points) / total_points
        estimates = np.append(estimates, pi_estimate)
        line_estimate.set_data(range(len(estimates)), estimates)
    
    return scatter_inside, scatter_outside, line_estimate

# Create and save animation
anim = FuncAnimation(fig, update, frames=200, interval=50, blit=True)
anim.save(DIR / "pi.gif", writer="pillow")
plt.close()
```

![](pi.gif)


# [Decision Making]{.flow} {.title}

## Travel Itinerary

[Question:]{.question} **How and in which order would you visit 10 cities by plane with minimal total distance?**

```{python}
#| echo: true
#| eval: true
#| output-location: fragment
import math
print(math.factorial(10))
```

. . .

[Question:]{.question} **What could be a strategy?**

## Brute Force  

- Try [every possibility]{.highlight}
- Total possible routes: 10! = **3,628,800**
- **Guaranteed** to find best solution

. . .

[Question:]{.question} **What could be the problem with this approach?**

## Greedy Algorithm

- **Example:** Always picking shortest next flight
- Make **locally optimal** choices
- [Does not change existing choices]{.highlight}
- Fast but may miss global optimum

## Hill Climbing

- [Iteratively improve solution]{.highlight}
- Like **climbing in fog**
- Check **all neighboring solutions**
- Can get stuck in **local optima**

## Simulated Annealing

- Make random changes and **accept improvements**
- Sometimes accept **worse solutions**
- Gradually become **more selective**

. . .

[Question:]{.question} **Why accept worse solutions sometimes?**

. . .

- Randomness helps to escape **local optima**
- Balances [exploration vs. exploitation]{.highlight}

## Simulated Annealing Animation

```{python}
#| echo: false
# Setup the figure with two subplots: main visualization and temperature
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(18, 8), height_ratios=[3, 1], dpi=150)
plt.subplots_adjust(hspace=0.3)

# Generate the objective function (parabola)
x = np.linspace(0, 10, 200)
y = -((x-5)**2)  # Parabola with maximum at x=5
ax1.plot(x, y, 'k-', alpha=0.3, label='Objective Function')

# Initialize starting position (random x between 0 and 10)
current_x = np.random.uniform(0, 10)
current_y = -((current_x-5)**2)
point, = ax1.plot([current_x], [current_y], 'ro', markersize=10, 
                  label='Current Position')

# Animation parameters
initial_temp = 10.0
temperature = initial_temp
cooling_rate = 0.995
path_x = [current_x]
path_y = [current_y]
temperatures = [temperature]

# Plot search path
line, = ax1.plot(path_x, path_y, 'r-', alpha=0.5, label='Search Path')

# Temperature plot
temp_line, = ax2.plot(temperatures, 'b-', label='Temperature')

def update(frame):
    global current_x, current_y, temperature
    
    # Propose new solution (larger steps when temperature is high)
    new_x = current_x + np.random.normal(0, temperature)
    new_x = np.clip(new_x, 0, 10)  # Keep within bounds
    new_y = -((new_x-5)**2)
    
    # Acceptance probability (higher temp = more likely to accept worse solutions)
    if new_y > current_y:  # Always accept better solutions
        acceptance = True
    else:
        prob = np.exp((new_y - current_y) / temperature)
        acceptance = np.random.random() < prob
    
    # Update position if accepted
    if acceptance:
        current_x = new_x
        current_y = new_y
    
    # Cool down system
    temperature *= cooling_rate
    
    # Update visualization
    path_x.append(current_x)
    path_y.append(current_y)
    temperatures.append(temperature)
    
    line.set_data(path_x, path_y)
    point.set_data([current_x], [current_y])
    temp_line.set_data(range(len(temperatures)), temperatures)
    
    # Update progress text
    progress = frame / 200 * 100
    ax1.set_title(f'Simulated Annealing Progress: {progress:.1f}%\n'
                  f'Current Temperature: {temperature:.2f}')
    
    return line, point, temp_line

# Setup axis limits and labels
ax1.set_xlim(0, 10)
ax1.set_ylim(-30, 5)
ax1.grid(True, alpha=0.3)
ax1.set_xlabel('Search Space')
ax1.set_ylabel('Objective Value')
ax1.legend(loc='upper right')

ax2.set_xlim(0, 200)
ax2.set_ylim(0, initial_temp)
ax2.grid(True, alpha=0.3)
ax2.set_xlabel('Iterations')
ax2.set_ylabel('Temperature')
ax2.set_title('Cooling Schedule')

# Create and save animation
anim = FuncAnimation(fig, update, frames=200, interval=50, blit=True)
anim.save(DIR / 'simulated_annealing.gif', writer='pillow')
plt.close()
```

![](simulated_annealing.gif)


# [Nature and Society]{.flow} {.title}

## Bacterial Evolution

[Question:]{.question} **Do bacteria "choose" to become resistant to antibiotics or is it random?**

. . .

::: {.callout-note}
## Salvador Luria's Experiment
- If adaptive: All bacteria would develop resistance
- If random: Only some colonies develop resistance
:::

. . .

[Result: Randomness wins!]{.highlight} 🦠

## Thought Experiment

[Question:]{.question} **What's more important for a society?**

. . .

::: {.columns}
::: {.column width="50%"}
[Freedom]{.highlight}

- Individual choice
- Personal responsibility
- Market-driven
:::

::: {.column width="50%"}
[Equality]{.highlight}

- Shared resources
- Social safety nets
- Regulated systems
:::
:::

. . .

[Question:]{.question} **Any problem with this question?**

## Veil of Ignorance

You might [randomly]{.highlight} be:

- Any gender identity and economic status
- Any health condition and intelligence level
- Any cultural background and religious belief

. . .

[Question:]{.question} **If you didn't know who you'd be born as, what kind of society would you design?**

# [Key Considerations]{.flow} {.title}

## Overview

1. **Impact of Policies**
2. **Measuring Societal Success**
3. **Data and Decision Making**

. . .

[Question:]{.question} **What would you consider in each of these?**

## Impact of Policies

- Small policy changes [can have cascading effects]{.highlight}
- **Example**: Changes in education funding affect generations

. . .

[Question:]{.question} **Do you have any other examples?**

## Data and Decision Making

- **Individual stories:** Powerful but potentially misleading
- **Statistics:** Comprehensive but can miss nuance
- **Hidden diversity:** Important subgroups may be overlooked

. . .

::: {.callout-important}
But that's not all! We also need to measure **success** and **failure**!
:::

## Measuring Success

- **Mean happiness:** Average well-being
- **Total happiness:** Utilitarian approach
- **Median happiness:** Focus on the middle class
- **Minimum happiness:** Protecting the most vulnerable

. . .

[Question:]{.question} **What could be the problem with these measures?**

## Solution: Random Sampling

- Randomly [select a subset of the population]{.highlight}
- Gather **diverse perspectives** from the sample
- **Reduce selection bias** and improve accuracy
- Better understand **needs** of population

## Selection Bias

[Question:]{.question} **How can randomness promote fairness?**

. . .

- **Randomly** selecting Jury of a trial
- **Random lottery** for college admissions
- **Random allocation** of patients in clinical trials

# [Uncertainty]{.flow} {.title}

## Decisions Under Uncertainty

[Question:]{.question} **When should we embrace vs. reduce randomness?**

. . .

::: {.columns}
::: {.column width="50%"}
[Embrace When]{.highlight}:

- Exploring new solutions
- Avoiding bias
- Breaking deadlocks
- Testing systems
:::

::: {.column width="50%"}
[Reduce When]{.highlight}:

- Safety-critical systems
- Financial transactions
- Medical procedures
- Legal proceedings
:::
:::

## Quick Poll
[Question:]{.question} **Which would you prefer?**

- **100% chance of winning $50**
- **50% chance of winning $120**

. . .

::: {.callout-tip}
Answer depends on your **risk aversion**!
:::

## Randomness and Creativity

- Random exposure to new ideas [sparks creativity]{.highlight}
- Changing contexts leads to novel solutions
- Balance between **randomness** and **structure**
- Balance between **exploration** and **exploitation**
- **Perfect information** is rare

## Life Lessons

1. **Embrace Uncertainty**
   - Perfect information is rare
   - Adapt to changing conditions

2. **Balance Exploration/Exploitation**
   - Try new things
   - Use what works
   - Know when to switch

3. **Accept "Good Enough"**
   - Perfect is enemy of good
   - Time is valuable
   - Consider opportunity costs

[Question:]{.question} **How do you balance these in your own life?**

## The End

::: {.callout-note}
**That's it for today's lecture!**\
We've covered the basics of randomness and its applications. In the upcoming tutorials, we'll implement these concepts in Python and explore their practical uses.
:::




