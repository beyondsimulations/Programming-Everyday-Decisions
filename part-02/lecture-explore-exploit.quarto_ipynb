{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Lecture II - Explore Vs. Exploit\"\n",
        "subtitle: \"Programming: Everyday Decision-Making Algorithms\"\n",
        "author: \"Dr. Nils Roemer\"\n",
        "institute: \"Kühne Logistics University Hamburg - Winter 2024\"\n",
        "title-slide-attributes:\n",
        "    data-background-color: \"#8C3048\"\n",
        "\n",
        "format:\n",
        "    revealjs:\n",
        "        theme: [default, ../styles.scss]\n",
        "        transition: slide\n",
        "        transition-speed: fast\n",
        "        highlight-style: arrow\n",
        "        code-overflow: wrap\n",
        "        slide-number: true\n",
        "        code-copy: true\n",
        "        height: 750\n",
        "        footer: \" {{< meta title >}} | {{< meta author >}} | [Home](lecture-optimal-stopping.qmd)\"\n",
        "        output-file: lecture-presentation.html\n",
        "    html:\n",
        "        theme: [litera, ../styles_html.scss]\n",
        "    pdf: \n",
        "        documentclass: report\n",
        "\n",
        "execute:\n",
        "    freeze: auto\n",
        "    echo: true\n",
        "---\n",
        "\n",
        "\n",
        "# [Explore Vs. Exploit]{.flow} {.title}\n",
        "\n",
        "## Some definitions...\n",
        "\n",
        "1) [Question:]{.question} What does \"explore\" mean?\n",
        "2) [Question:]{.question} What does \"exploit\" mean?\n",
        "3) [Question:]{.question} what is the relationship between ‘explore’ and ‘exploit’ ?\n",
        "\n",
        ":::{.incremental}\n",
        "1) [Explore]{.highlight} is the gathering of new information\n",
        "2) [Exploit]{.highlight} exploit is the utilisation of already known information in order to obtain a known result.\n",
        "3) [Explore and exploit]{.highlight} are opposing action alternatives in a trade-off.\n",
        ":::\n",
        "\n",
        "## Some examples...\n",
        "\n",
        "[Your stomach rumbles...]{.highlight}\n",
        "    - Do you go to the italian restaurant, that you know and love?\n",
        "    - Or do you try the new restaurant down the road, that you have never been to before?\n",
        "    - Do you take your best friend with you?\n",
        "    - Or are you asking a new acquaintance that you would like to get to know better?\n",
        "[This is too hard, maybe you'll just stay at home and cook]{.highlight}\n",
        "    - Do you cook your favorite meal?\n",
        "    - Or do you try a new recipe from the internet that you have never cooked before?\n",
        "    - ...\n",
        "\n",
        "## Everyday decision-making\n",
        "\n",
        "- Explore: Do we try new things?\n",
        "- Exploit: Do we stick to our favorite ones?\n",
        "- Live is a trade-off, a balance:\n",
        "    - between novelty and tradition.\n",
        "    - between the latest and the greatest.\n",
        "    - between explore and exploit.\n",
        "- [Question:]{.question} What is the optimal balance?\n",
        "- Computer scientists have been working on this problem for over 50 years.\n",
        "\n",
        "## [Question:]{.question} What is the problem with exploitation?\n",
        "\n",
        "- Exploitation is not always the best strategy.\n",
        "- Especially when you have very limited information.\n",
        "- When you stop exploring, you might miss out on better options.\n",
        "- Imagine you were no longer able to gather any new information and could only choose between known alternatives. \n",
        "\n",
        "## [Question:]{.question} What is the problem with exploration?\n",
        "\n",
        "- Exploration is not always the best strategy.\n",
        "- Especially when you are limited to use the new gathered information.\n",
        "- When you constantly explore, you might never enjoy the fruits of your exploration.\n",
        "- Imagine you could eat each meal only once, hear each song only once, talk to each person only once...\n",
        "\n",
        "## To provide decision support, computer scientists formulated the explore-exploit trade-off as the multi-armed bandit problem.\n",
        "\n",
        "[Question:]{.question} What is a one-armed bandit?\n",
        "\n",
        "## [One Armed Bandit]{.invert-font} {background-image=\"https://images.unsplash.com/photo-1578693988706-534015857ff5?q=80&w=2664&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"}\n",
        "::: footer\n",
        "[Photo by <a href=\"https://unsplash.com/de/@evoknow\">Kabir M</a> on Unsplash]{.invert-font}\n",
        ":::\n",
        "\n",
        "## The multi-armed bandit problem I\n",
        "\n",
        "- A gambler is faced with a room of slot machines (one-armed bandits).\n",
        "- Each slot machine has a different probability of winning.\n",
        "- [Question:]{.question} What does the scenario have to do with explore vs exploit?\n",
        "\n",
        "## The multi-armed bandit problem II\n",
        "\n",
        "- By playing a slot machine, the gambler can gather information about the probability of winning.\n",
        "- But each pull of a lever comes with a certain cost.\n",
        "- It's the aim of the gambler to maximise his winnings.\n",
        "- [Question:]{.question} What is the optimal strategy?\n",
        "\n",
        "## The multi-armed bandit problem III\n",
        "\n",
        "- Consider the following scenario:\n",
        "    - You already pulled the lever of two machines.\n",
        "    - Machine A: 15 pulls, 9 wins.\n",
        "    - Machine B: 2 pulls, 1 win.\n",
        "- [Question:]{.question} Which machine should you play next?\n",
        "\n",
        "## Expected value as a decision criterion\n",
        "\n",
        "- The expected value of a slot machine is the average number of wins per pull.\n",
        "- Expected value of machine A = E(A) = 9/15 = 0.6\n",
        "- Expected value of machine B = E(B) = 1/2 = 0.5\n",
        "- Machine A has the higher expected value.\n",
        "- But 2 and even 15 pulls are not a large number (considering standard deviation).\n",
        "\n",
        "## The multi-armed bandit problem IV\n",
        "\n",
        "- The multi-armed bandit problem represents a lot of different real-world decisions.\n",
        "- It shows us, that there might be a difference between the optimal long-term average performance and the optimal immediate performance.\n",
        "- Which lever to pull next depends completely on something we havent discussed yet: \n",
        "\n",
        "## The multi-armed bandit problem V\n",
        "- How long you plan to be in the casino?\n",
        "- [Question:]{.question} Why is this important?\n",
        "- [Question:]{.question} How does this influence our decision on taking machine A or machine B?\n",
        "- \"I'm more likely to try a new restaurant when I move to a city than when I'm leaving it\" (Chris Stucchio)\n",
        "\n",
        "## The influence of the interval\n",
        "\n",
        "- Let's call the time you plan to be in the casino \"the interval\".\n",
        "- The longer the interval, the more (in general) you should explore, since you will have more opportunities to exploit the gathered information.\n",
        "- The shorter the interval, the more you should exploit your current knowledge.\n",
        "- The optimal strategy depends on the length of the interval.\n",
        "\n",
        "## The interval makes the strategy\n",
        "\n",
        "- Explore when you have the time to use the resulting knowledge.\n",
        "- \"I moved to Pune, India, and I just [...] eat everywhere that didn't look like it was gonna kill me\" (Chris Stucchio)\n",
        "- Exploit when you are ready to cash in.\n",
        "- \"And as I was leaving the city I went back to all my old favorites, rather than trying out new stuff [...]. Even if I find a slightly better place, I'm only going to go there once or twice, so why take the risk?\" (Chris Stucchio)\n",
        "\n",
        "## Reality check: Explore vs Exploit.\n",
        "\n",
        "## [Exploration]{.invert-font} {background-image=\"https://images.unsplash.com/photo-1491013516836-7db643ee125a?q=80&w=2650&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"}\n",
        "::: footer\n",
        "[Photo by <a href=\"https://unsplash.com/de/@invent\">Colin Maynard</a> on Unsplash]{.invert-font}\n",
        ":::\n",
        "\n",
        "## [Exploitation]{.invert-font} {background-image=\"https://images.unsplash.com/photo-1504004030892-d06adf9ffbcf?q=80&w=2670&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"}\n",
        "\n",
        "::: footer\n",
        "[Photo by <a href=\"https://unsplash.com/de/@cristina_gottardi\">Cristina Gottardi</a> on Unsplash]{.invert-font}\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Reverse Engineering: Derivation of the interval by observing the strategy (excursion)\n",
        "\n",
        "- Among the the ten highest-grossing movies, how many were sequels?\n",
        "    - 1981: 2\n",
        "    - 1991: 3\n",
        "    - 2001: 5\n",
        "    - 2011: 8\n",
        "- [Question:]{.question} Do you have an explanation for the observed trend?\n",
        "\n",
        "## [Sequels...]{.invert-font} {background-image=\"https://upload.wikimedia.org/wikipedia/commons/3/3d/Fast_X_logo.png\" background-size=\"contain\" background-position=\"center\" background-repeat=\"no-repeat\"}\n",
        "\n",
        "::: footer\n",
        "[Photo by <a href=\"https://de.wikipedia.org/wiki/Fast_%26_Furious_10\">Universal Pictures</a> on Wikipedia]{.invert-font}\n",
        ":::\n",
        "\n",
        "## Reverse Engineering: A possible explanation\n",
        "\n",
        "- Making a brand new movie is risky but has the potential to create a new fan base. (explore)\n",
        "- From a Studio's perspective, a sequel is a movie with a guaranteed fan base, a cash cow, a sure thing, an exploit.\n",
        "- One possible explanation for the numbers is that the studios think they are approaching the end of their interval. \n",
        "- They are pulling the arms of the best machines they've got before the casino turns them out.\n",
        "\n",
        "## The multi-armed bandit problem VI\n",
        "\n",
        "- While the so far provided anecdotes are helping us to understand the explore-exploit trade-off, they are far away from beeing a satisfying \"optimal\" solution.\n",
        "- Actually, finding an algorithm that tells us exactly how to to handle the trade-off is a very hard problem.\n",
        "- On the way there were many interesting approaches...\n",
        "\n",
        "## Win-Stay Lose-Shift[^1]\n",
        "\n",
        "- The win-stay lose-shift strategy is a simple strategy that is often used in multi-armed bandit problems.\n",
        "- It is based on the idea that if you have won, you should stay with the same machine.\n",
        "- If you have lost, you should switch to a different machine.\n",
        "- This strategy is not always the best strategy, but it is simple and proven better than choose an arm at random.\n",
        "- [Question:]{.question} How would you test this proof using Python?\n",
        "\n",
        "...\n",
        "\n",
        "[^1]: For more details see Robbins, H. (1952) ‘Some aspects of the sequential design of experiments’, Bulletin of the American Mathematical Society, 58. \n",
        "\n",
        "## Win-Stay is a no brainer\n",
        "\n",
        "- If you decide to pull an arm and you win, you should pull the same arm again.\n",
        "- Nothing changes, except the attractiveness of the arm you just pulled is higher.\n",
        "\n",
        "## Lose-Shift is another story\n",
        "\n",
        "- Changing arms each time you lose might be a prety rush move.\n",
        "- Imagine you're eating at your favorite restaurant for the tenth time in a row. \n",
        "- You have always been very satisfied (win), but today you are disappointed (loose). \n",
        "- Should you turn your back on the restaurant?\n",
        "\n",
        "## Like most of the time, easy answers comes with problems\n",
        "\n",
        "- The win-stay lose-shift strategy penalizes loses to much.\n",
        "- The strategy does not take into account the interval.\n",
        "- But the strategy laid the foundation for better approaches\n",
        "\n",
        "## The Bellman approach I\n",
        "\n",
        "- Few years later, Richard Bellman, found an exact solution to the problem for all cases with finite and known intervals.\n",
        "- Bellman found, that under the given assumptions, exploit vs explore can be formulated as optimal stopping problem.\n",
        "- Where the question is, when to stop exploring and start exploiting.\n",
        "- The solution is based on dynamic programming and backward calculation starting from the final pull (analogous to the secretary problem with full-information).\n",
        "\n",
        "## The Bellman approach II\n"
      ],
      "id": "84a2fadf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "#| output: asis\n",
        "\n",
        "print(\"\"\"\n",
        "```mermaid\n",
        "graph TD\n",
        "    D1[Decision 1] --> |Result A| D2A[Decision 2A]\n",
        "    D1 --> |Result B| D2B[Decision 2B]\n",
        "    \n",
        "    D2A --> |Result A| D3A[Decision 3A]\n",
        "    D2A --> |Result B| D3B[Decision 3B]\n",
        "    D2B --> |Result A| D3C[Decision 3C]\n",
        "    D2B --> |Result B| D3D[Decision 3D]\n",
        "    \n",
        "    D3A --> |Result A| D4A[Decision 4A]\n",
        "    D3A --> |Result B| D4B[Decision 4B]\n",
        "    D3B --> |Result A| D4C[Decision 4C]\n",
        "    D3B --> |Result B| D4D[Decision 4D]\n",
        "    D3C --> |Result A| D4E[Decision 4E]\n",
        "    D3C --> |Result B| D4F[Decision 4F]\n",
        "    D3D --> |Result A| D4G[Decision 4G]\n",
        "    D3D --> |Result B| D4H[Decision 4H]\n",
        "    \n",
        "    D4A --> |Result A| D5A[5A]\n",
        "    D4A --> |Result B| D5B[5B]\n",
        "    D4B --> |Result A| D5C[5C]\n",
        "    D4B --> |Result B| D5D[5D]\n",
        "    D4C --> |Result A| D5E[5E]\n",
        "    D4C --> |Result B| D5F[5F]\n",
        "    D4D --> |Result A| D5G[5G]\n",
        "    D4D --> |Result B| D5H[5H]\n",
        "    D4E --> |Result A| D5I[5I]\n",
        "    D4E --> |Result B| D5J[5J]\n",
        "    D4F --> |Result A| D5K[5K]\n",
        "    D4F --> |Result B| D5L[5L]\n",
        "    D4G --> |Result A| D5M[5M]\n",
        "    D4G --> |Result B| D5N[5N]\n",
        "    D4H --> |Result A| D5O[5O]\n",
        "    D4H --> |Result B| D5P[5P]"
      ],
      "id": "0d7f0202",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\"\"\")\n",
        "```\n",
        "\n",
        "## The Bellman approach III\n",
        "\n",
        "- The calculation of the optimal strategy are very extensive when there are many arms and a long interval.\n",
        "- And yet the approach does not help us in many scenarios because we do not know the exact number of opportunities  / time in the casino (length of the interval).\n",
        "- At this point, it looked like the multi-armed bandit problem would remain a problem without a solution.\n",
        "\n",
        "## The Gittins Index I[^2]\n",
        "\n",
        "- In the 1970s, the Unilever Corporation asked a young mathematician, John Gittins, to help optimize their drug trials.\n",
        "- Given several different chemical compounds, what is the quickest way to determine which compound is likely to be effective against a disease?\n",
        "- Gittins found an optimal strategy, abstracted the problem to a general level, and realized that what he had discovered was, in fact, the solution to the multi-armed bandit problem.\n",
        "\n",
        "[^2]: Gittins, J. (1979) ‘Bandit Processes and Dynamic Allocation Indices’, Journal of the Royal Statistical Society. Series B (Methodological). 41 (2).\n",
        "\n",
        "## The Gittins Index II\n",
        "\n",
        "- A major problem with the multi-armed banded problem is that previous solutions made very critical assumptions about the underlying interval.\n",
        "- For example, that the length of the interval is known at the beginning of the analysis.\n",
        "- Gittins developed a charming solution to this problem. In his approach, future wins (e.g. cash flows) are discounted[^3] so that any interval length (including infinity) can be considered. \n",
        "\n",
        "...\n",
        "\n",
        "[^3]: Gittins makes a geometric discounting assumption, but the approach can be extended to other discounting assumptions.\n",
        "\n",
        "## Reality check: Discounting\n",
        "\n",
        "- Does discounting future wins make sense?\n",
        "- Regarding monetary wins, it does. For example due to interest rates and oppurtunity costs.\n",
        "- Regarding non-monetary wins, it is more difficult to justify.\n",
        "- But its not counterintuitive.\n",
        "- What is more important to you today, tonight's dinner, or ceteris paribus the dinner in a week's time?\n",
        "\n",
        "## The Gittins Index III\n",
        "\n",
        "- The Gittins index can be used to any problems of the form of the multi-armed bandit problem.\n",
        "- That means it solves the explore-exploit trade-off.\n",
        "- It is optimal.\n",
        "\n",
        "## Explore vs Exploit: Summary I \n",
        "\n",
        "- Consider an explore vs exploit decision situation.\n",
        "- As you learned exploiting comes with a known (expected) outcome for example E(A) = 0.6.\n",
        "- Exploring comes with an unknown outcome E(B) = ?.\n",
        "- What should you do according to decision science?\n",
        "    \n",
        "## Explore vs Exploit: Summary II\n",
        "\n",
        "- Anecdotally:\n",
        "    - If you have a long interval, you should explore, choose B untill you are sure about E(B).\n",
        "    - If you have a short interval, you should exploit, choose A.\n",
        "- Mathematically:\n",
        "    - If E(A) and E(B) are known, choose the higher expected value.\n",
        "    - If E(B) is unknown, but you know the length of the interval, the Bellman-approach provides the optimal strategy.\n",
        "    - If E(B) is unknown, and you do not know the length of the interval, the Gittins index provides the optimal strategy."
      ],
      "id": "0d7169c7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\NilsRoemer\\AppData\\Local\\Programs\\Python\\Python313\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}