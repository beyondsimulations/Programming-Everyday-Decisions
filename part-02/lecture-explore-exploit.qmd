---
title: "Lecture II - Explore Vs. Exploit"
subtitle: "Programming: Everyday Decision-Making Algorithms"
author: "Dr. Nils Roemer"
institute: "Kühne Logistics University Hamburg - Winter 2024"
title-slide-attributes:
    data-background-color: "#8C3048"

format:
    revealjs:
        theme: [default, ../styles.scss]
        transition: slide
        transition-speed: fast
        highlight-style: arrow
        code-overflow: wrap
        slide-number: true
        code-copy: true
        height: 750
        footer: " {{< meta title >}} | {{< meta author >}} | [Home](lecture-explore-exploit.qmd)"
        output-file: lecture-presentation.html
    html:
        theme: [litera, ../styles_html.scss]

execute:
    freeze: auto
    echo: true
---

# [Explore Vs. Exploit]{.flow} {.title}

## Some definitions...
:::{.incremental}
1) [Question:]{.question} What does "explore" mean?
2) [Question:]{.question} What does "exploit" mean?
3) [Question:]{.question} what is the relationship between ‘explore’ and ‘exploit’ ?

1) [Explore]{.highlight} is the gathering of new information.
2) [Exploit]{.highlight} is the utilization of already known information to obtain a known result.
3) [Explore and exploit]{.highlight} are opposing alternatives in a trade-off.
:::

## Some examples...
:::{.incremental}
- Clinical trials
- A/B testing
- Restaurant choice
- Dating
- Social interactions
:::

## Everyday decision-making
:::{.incremental}
- Explore: Do we try new things?
- Exploit: Do we stick to our favorite ones?
- Life is a trade-off, a balance:
    - between novelty and tradition.
    - between the latest and the greatest.
    - between explore and exploit.
- [Question:]{.question} What is the optimal balance?
- Scientists have been working on this for over 50 years.
:::

## [Question:]{.question} What is the problem with exploitation?
:::{.incremental}
- Exploitation is not always the best strategy.
- Especially when you have very limited information.
- When you stop exploring, you might miss out on better options.
- Imagine you were no longer able to gather any new information and could only choose between known alternatives.
:::

## [Question:]{.question} What is the problem with exploration?
:::{.incremental}
- Exploration is not always the best strategy.
- Especially when you are limited in using the newly gathered information.
- When you constantly explore, you might never enjoy the fruits of your exploration.
- Imagine you could eat each meal only once, hear each song only once, talk to each person only once...
:::

# [The Multi-Armed Bandit Problem]{.flow} {.title}

## To provide decision support, computer scientists formulated the explore-exploit trade-off as the multi-armed bandit problem.

[Question:]{.question} What is a one-armed bandit?

## [One Armed Bandit]{.invert-font} {background-image="https://images.unsplash.com/photo-1578693988706-534015857ff5?q=80&w=2664&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"}
::: footer
[Photo by <a href="https://unsplash.com/de/@evoknow">Kabir M</a> on Unsplash]{.invert-font}
:::

## The multi-armed bandit problem I
:::{.incremental}
- A gambler is faced with a room of slot machines (one-armed bandits).
- Each slot machine has a different probability of winning.
- [Question:]{.question} What does the scenario have to do with explore vs exploit?
:::

## The multi-armed bandit problem II

:::{.incremental}
- By playing a slot machine, the gambler can gather information about the probability of winning.
- But each pull of a lever comes with a certain cost.
- It's the aim of the gambler to maximize his winnings.
:::

## The multi-armed bandit problem III
:::{.incremental}
- Consider the following scenario:
    - You already pulled the lever of two machines.
    - Machine A: 15 pulls, 9 wins.
    - Machine B: 2 pulls, 1 win.
- [Question:]{.question} Which machine should you play next?
:::

## Expected value as a decision criterion
:::{.incremental}
- The expected value of a slot machine is the average number of wins per pull.
- Expected value of machine A = E(A) = 9/15 = 0.6
- Expected value of machine B = E(B) = 1/2 = 0.5
- Machine A has the higher expected value.
- But 2 and even 15 pulls are not a large number (considering standard deviation).
:::

## The multi-armed bandit problem IV

:::{.incremental}
- The multi-armed bandit problem represents a lot of different real-world decisions.
- It shows us, that there might be a difference between the optimal long-term average performance and the optimal immediate performance.
- Which lever to pull next depends completely on something we haven't discussed yet: 
:::

## The multi-armed bandit problem V

:::{.incremental}
- How long you plan to be in the casino?
- [Question:]{.question} Why is this important?
- [Question:]{.question} How does this influence our decision on taking machine A or machine B?
:::

. . .

> "I'm more likely to try a new restaurant when I move to a city than when I'm leaving it" (Chris Stucchio)

## The influence of the interval

:::{.incremental}
- Let's call the time you plan to be in the casino "the interval".
- The longer the interval, the more (in general) you should explore, since you will have more opportunities to exploit the gathered information.
- The shorter the interval, the more you should exploit your current knowledge.
- The optimal strategy depends on the length of the interval.
:::

## Interval and Exploration

- Explore when you have the time to use the resulting knowledge.

. . .

> "I moved to Pune, India, and I just [...] eat everywhere that didn't look like it was gonna kill me" (Chris Stucchio)


## Interval and Exploitation

- Exploit when you are ready to cash in.

. . .

> "And as I was leaving the city I went back to all my old favorites, rather than trying out new stuff [...]. Even if I find a slightly better place, I'm only going to go there once or twice, so why take the risk?" (Chris Stucchio)

# [Exploration and Exploitation]{.flow} {.title}

## [Exploration]{.invert-font} {background-image="https://images.unsplash.com/photo-1491013516836-7db643ee125a?q=80&w=2650&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"}
::: footer
[Photo by <a href="https://unsplash.com/de/@invent">Colin Maynard</a> on Unsplash]{.invert-font}
:::

## [Exploitation]{.invert-font} {background-image="https://images.unsplash.com/photo-1504004030892-d06adf9ffbcf?q=80&w=2670&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"}

::: footer
[Photo by <a href="https://unsplash.com/de/@cristina_gottardi">Cristina Gottardi</a> on Unsplash]{.invert-font}
:::

## Reverse Engineering


:::{.incremental}
- Derivation of the interval by observing the strategy
- Among the the ten highest-grossing movies, how many were sequels?
    - 1981: 2
    - 1991: 3
    - 2001: 5
    - 2011: 8
- [Question:]{.question} Do you have an explanation for the trend?
:::

## [Sequels...]{.invert-font} {background-image="https://upload.wikimedia.org/wikipedia/commons/3/3d/Fast_X_logo.png" background-size="contain" background-position="center" background-repeat="no-repeat"}

::: footer
[Photo by <a href="https://de.wikipedia.org/wiki/Fast_%26_Furious_10">Universal Pictures</a> on Wikipedia]{.invert-font}
:::

## Reverse Engineering: A possible explanation
:::{.incremental}
- Making a brand new movie is risky but has the potential to create a new fan base. (explore)
- From a Studio's perspective, a sequel is a movie with a guaranteed fan base, a cash cow, a sure thing, an exploit.
- One possible explanation for the numbers is that the studios think they are approaching the end of their interval. 
- They are pulling the arms of the best machines they've got before the casino turns them out.
:::

## The multi-armed bandit problem VI

:::{.incremental}
- While the so far provided anecdotes are helping us to understand the explore-exploit trade-off, they are far away from beeing a satisfying "optimal" solution.
- Actually, finding an algorithm that tells us exactly how to to handle the trade-off is a very hard problem.
- On the way there were many interesting approaches...
:::

# [Win-Stay Lose-Shift]{.flow} {.title}

## Win-Stay Lose-Shift[^1]

:::{.incremental}
- The win-stay lose-shift strategy is a simple strategy that is often used in multi-armed bandit problems.
- It is based on the idea that if you have won, you should stay with the same machine.
- If you have lost, you should switch to a different machine.
- This strategy is not always the best strategy, but it is simple and proven better than choose an arm at random.
:::

[^1]: For more details see Robbins, H. (1952) ‘Some aspects of the sequential design of experiments’, Bulletin of the American Mathematical Society, 58. 

## Win-Stay is a no brainer

:::{.incremental}
- If you decide to pull an arm and you win, you should pull the same arm again.
- Nothing changes, except the attractiveness of the arm you just pulled is higher.
:::

## Lose-Shift is another story

:::{.incremental}
- Changing arms each time you lose might be a prety rush move.
- Imagine you're eating at your favorite restaurant for the tenth time in a row. 
- You have always been very satisfied (win), but today you are disappointed (loose). 
- Should you turn your back on the restaurant?
:::

## Like most of the time, easy answers comes with problems

:::{.incremental}
- The win-stay lose-shift strategy penalizes losses too much.
- The strategy does not take into account the interval.
- But the strategy laid the foundation for better approaches
:::

# [The Bellman Approach]{.flow} {.title}

## The Bellman approach I

:::{.incremental}
- Few years later, Richard Bellman, found an exact solution to the problem for all cases with finite and known intervals.
- Bellman found that under the given assumptions, exploit vs explore can be formulated as an optimal stopping problem.
- Where the question is, when to stop exploring and start exploiting.
- The solution is based on dynamic programming and backward calculation starting from the final pull (analogous to the secretary problem with full information).
:::

## The Bellman approach II

:::{.incremental}
- Consider the example with machine A and B again.
- The following graph shows the possible outcomes of the next 4 pulls at machine B.
- When should we stop exploring and start exploiting?
:::

## The Bellman approach III

::: {.cell style="text-align: center;"}

```{mermaid}
%%| echo: false
graph TD
    D1(["(1,1)"]) --> |Win| D2A(["(2,1)"])
    D1 --> |Lose| D2B(["(1,2)"])
    
    D2A --> |Win| D3AA(["(3,1)"])
    D2A --> |Lose| D3AB(["(2,2)"])
    D2B --> |Win| D3AB(["(2,2)"])
    D2B --> |Lose| D3BB(["(1,3)"])
    
    D3AA --> |Win| D4AAA(["(4,1)"])
    D3AA --> |Lose| D4AAB(["(3,2)"])
    D3AB --> |Win| D4AAB(["(3,2)"])
    D3AB --> |Lose| D4ABB(["(2,3)"])
    D3BB --> |Win| D4ABB(["(2,3)"])
    D3BB --> |Lose| D4BBB(["(1,4)"])
    
    D4AAA --> |Win| D5AAAA(["(5,1)"])
    D4AAA --> |Lose| D5AAAB(["(4,2)"])
    D4AAB --> |Win| D5AAAB(["(4,2)"])
    D4AAB --> |Lose| D5AABB(["(3,3)"])
    D4ABB --> |Win| D5AABB(["(3,3)"])
    D4ABB --> |Lose| D5ABBB(["(2,4)"])
    D4BBB --> |Win| D5ABBB(["(2,4)"])
    D4BBB --> |Lose| D5BBBB(["(1,5)"])
```
:::

## The Bellman approach IV

::: {.cell style="display: flex; justify-content: center;"}
<style>
table {
    border-collapse: collapse;
    font-size: 24px;
    font-family: "Courier New", Courier, monospace;
}
th, td {
    border: 1px solid #ddd;
    padding: 8px;
    text-align: right;
    min-width: 60px;
}
th {
    background-color: #f4f4f4;
    text-align: center;
}
th:first-child, td:first-child {
    text-align: center;
    font-weight: bold;
}
</style>

| Loses/Wins | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 |
|------------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|
| 1 | 0.50 | 0.60 | 0.67 | 0.71 | 0.75 | 0.78 | 0.80 | 0.82 | 0.83 | 0.85 |
| 2 | 0.40 | 0.50 | 0.57 | 0.63 | 0.67 | 0.70 | 0.73 | 0.75 | 0.77 | 0.79 |
| 3 | 0.33 | 0.43 | 0.50 | 0.56 | 0.60 | 0.64 | 0.67 | 0.69 | 0.71 | 0.73 |
| 4 | 0.29 | 0.38 | 0.44 | 0.50 | 0.55 | 0.58 | 0.62 | 0.64 | 0.67 | 0.69 |
| 5 | 0.25 | 0.33 | 0.40 | 0.45 | 0.50 | 0.54 | 0.57 | 0.60 | 0.63 | 0.65 |
| 6 | 0.22 | 0.30 | 0.36 | 0.42 | 0.46 | 0.50 | 0.53 | 0.56 | 0.59 | 0.61 |
| 7 | 0.20 | 0.27 | 0.33 | 0.38 | 0.43 | 0.47 | 0.50 | 0.53 | 0.56 | 0.58 |
| 8 | 0.18 | 0.25 | 0.31 | 0.36 | 0.40 | 0.44 | 0.47 | 0.50 | 0.53 | 0.55 |
| 9 | 0.17 | 0.23 | 0.29 | 0.33 | 0.38 | 0.41 | 0.44 | 0.47 | 0.50 | 0.52 |
| 10 | 0.15 | 0.21 | 0.27 | 0.31 | 0.35 | 0.39 | 0.42 | 0.45 | 0.48 | 0.50 |
:::

## The Bellman approach V

Calculated with the following equation:
$$
\mathbb{E}[B] = \frac{w + 1}{w + l + 2}
$$
where w is the number of wins and l is the number of loses.

## The Bellman approach VI

:::{.incremental}
- The calculation of the optimal strategy is very extensive when there are many arms and a long interval.
- And yet the approach does not help us in many scenarios because we do not know the exact number of opportunities/time in the casino (length of the interval).
- At this point, it looked like the multi-armed bandit problem would remain a problem without a solution.
:::

# [The Gittins Index]{.flow} {.title}

## The Gittins Index I[^2]

:::{.incremental}
- In the 1970s Unilever asked a young mathematician, John Gittins, to help optimize their drug trials.
- Given different compounds, what is the quickest way to determine which is likely to be effective?
- Gittins found an optimal strategy and abstracted the problem to a general level.
- He found the solution to the multi-armed bandit problem.

[^2]: Gittins, J. (1979) ‘Bandit Processes and Dynamic Allocation Indices’, Journal of the Royal Statistical Society. Series B (Methodological).
:::

## The Gittins Index II

:::{.incremental}
- A major problem with the multi-armed banded problem is that previous solutions made very critical assumptions about the underlying interval.
- For example, that the length of the interval is known at the beginning of the analysis.
- Gittins developed a charming solution to this problem. In his approach, future wins (e.g., cash flows) are discounted so that any interval length (including infinity) can be considered.

[^3]: Gittins makes a geometric discounting assumption, but the approach can be extended to other discounting assumptions.
:::

## Reality check: Discounting

:::{.incremental}
- Does discounting future wins make sense?
- Regarding monetary wins, it does. For example, due to interest rates and opportunity costs.
- Regarding non-monetary wins, it is more difficult to justify.
- But its not counterintuitive.
- What is more important to you today, tonight's dinner, or ceteris paribus the dinner in a week's time?
:::

## The Gittins Index III

:::{.incremental}
- The Gittins index can be used for any problems of the form of the multi-armed bandit problem.
- That means it solves the explore-exploit trade-off.
- Let's consider our machine A and B example one last time.
:::

## The Gittins Index IV

:::{.incremental}
- The Gittins index considers a discount factor of 90%.
- Clear win-stay but no lose-shift pattern.
- At (0,0) we see the exploration bonus (premium).
- Convergence to 1/2 for a 50/50 chance game.
:::

## The Gittins Index V

::: {.cell style="display: flex; justify-content: center;"}
<style>
table {
    border-collapse: collapse;
    font-size: 24px;
    font-family: "Courier New", Courier, monospace;
}
th, td {
    border: 1px solid #ddd;
    padding: 8px;
    text-align: right;
    min-width: 60px;
}
th {
    background-color: #f4f4f4;
    text-align: center;
}
th:first-child, td:first-child {
    text-align: center;
    font-weight: bold;
}
</style>

| Loses/Wins | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|------------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|
| 0 | .7029 | .8001 | .8452 | .8723 | .8905 | .9039 | .9141 | .9221 | .9287 | .9342 |
| 1 | .5001 | .6346 | .7072 | .7539 | .7869 | .8115 | .8307 | .8461 | .8588 | .8695 |
| 2 | .3796 | .5163 | .6010 | .6579 | .6996 | .7318 | .7573 | .7782 | .7956 | .8103 |
| 3 | .3021 | .4342 | .5184 | .5809 | .6276 | .6642 | .6940 | .7187 | .7396 | .7573 |
| 4 | .2488 | .3720 | .4561 | .5179 | .5676 | .6071 | .6395 | .6666 | .6899 | .7101 |
| 5 | .2103 | .3245 | .4058 | .4677 | .5168 | .5581 | .5923 | .6212 | .6461 | .6677 |
| 6 | .1815 | .2871 | .3647 | .4257 | .4748 | .5156 | .5510 | .5811 | .6071 | .6300 |
| 7 | .1591 | .2569 | .3308 | .3900 | .4387 | .4795 | .5144 | .5454 | .5723 | .5960 |
| 8 | .1413 | .2323 | .3025 | .3595 | .4073 | .4479 | .4828 | .5134 | .5409 | .5652 |
| 9 | .1269 | .2116 | .2784 | .3332 | .3799 | .4200 | .4548 | .4853 | .5125 | .5373 |
:::

## The Gittins Index VI

::: {.cell style="display: flex; justify-content: center;"}
<style>
table {
    border-collapse: collapse;
    font-size: 24px;
    font-family: "Courier New", Courier, monospace;
}
th, td {
    border: 1px solid #ddd;
    padding: 8px;
    text-align: right;
    min-width: 60px;
}
th {
    background-color: #f4f4f4;
    text-align: center;
}
th:first-child, td:first-child {
    text-align: center;
    font-weight: bold;
}
</style>

| Loses/Wins | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|------------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|
| 0 | .7029 | .8001 | .8452 | .8723 | .8905 | .9039 | .9141 | .9221 | .9287 | .9342 |
| 1 | .5001 | .6346 | .7072 | .7539 | .7869 | .8115 | .8307 | .8461 | .8588 | .8695 |
| 2 | .3796 | .5163 | .6010 | .6579 | .6996 | .7318 | .7573 | .7782 | .7956 | .8103 |
| 3 | .3021 | .4342 | .5184 | .5809 | .6276 | .6642 | .6940 | .7187 | .7396 | .7573 |
| 4 | .2488 | .3720 | .4561 | .5179 | .5676 | .6071 | .6395 | .6666 | .6899 | .7101 |
| 5 | .2103 | .3245 | .4058 | .4677 | .5168 | .5581 | .5923 | .6212 | .6461 | .6677 |
| 6 | .1815 | .2871 | .3647 | .4257 | .4748 | .5156 | .5510 | .5811 | .6071 | .6300 |
| 7 | .1591 | .2569 | .3308 | .3900 | .4387 | .4795 | .5144 | .5454 | .5723 | .5960 |
| 8 | .1413 | .2323 | .3025 | .3595 | .4073 | .4479 | .4828 | .5134 | .5409 | .5652 |
| 9 | .1269 | .2116 | .2784 | .3332 | .3799 | .4200 | .4548 | .4853 | .5125 | .5373 |
:::

. . .

[Question:]{.question} What does the Gittins index tell us about the trade-off between machine A and B?


## The Gittins Index VII

:::{.incremental}
- The problem with the Gittins index is that it is very difficult to calculate.
- See the following equation:
$$G_i(s_i, f_i) := \sup_{\tau \geq 1} \frac{\mathbb{E}\left[\sum_{t=0}^{\tau-1} \beta^t \cdot r_i^t \middle| s_i, f_i\right]}{\mathbb{E}\left[\sum_{t=0}^{\tau-1} \beta^t\right]}$$
- Where $G_i(s_i, f_i)$ is the Gittins index for machine $i$, $s_i$ is the number of wins, $f_i$ is the number of losses, $\beta$ is the discount factor, and $r_i^t$ is the reward for machine $i$ at time $t$.
:::

# [Explore vs Exploit: Summary]{.flow} {.title}

## Explore vs Exploit: Summary

:::{.incremental}
- Consider an explore vs exploit decision situation.
- As you learned exploiting comes with a known (expected) outcome for example E(A) = 0.6.
- Exploring comes with an unknown outcome E(B) = ?.
- What should you do according to decision science?
:::

## Explore vs Exploit: Anecdotally

:::{.incremental}
- If you have a long interval, you should explore, choose B untill you are sure about E(B).
- If you have a short interval, you should exploit, choose A.
:::

## Explore vs Exploit: Mathematically

:::{.incremental}
- If E(A) and E(B) are known, choose higher expected value.
- If E(B) is unknown, but you know the length of the interval, the Bellman-approach provides the optimal strategy.
- If E(B) is unknown, and you do not know the length of the interval, the Gittins index provides the optimal strategy.
:::

## Explore vs Exploit: Key Takeaways

> "The grass is always greener on the other side of the fence."

:::{.incremental}
- The math tells us why:
- Exploration in it self has a value, since trying new things increases our chance of finding the best.
- Your todays takeaway from the lecture should be: Be sensitive to how much time you have left in the casino and **explore, explore, explore**...
:::

# [Literature]{.flow} {.title}

## Interesting literature to start

- Christian, B., & Griffiths, T. (2016). Algorithms to live by: the computer science of human decisions. First international edition. New York, Henry Holt and Company.[^4]
- Ferguson, T.S. (1989) ‘Who solved the secretary problem?’, Statistical Science, 4(3). doi:10.1214/ss/1177012493. 

[^4]: The main inspiration for this lecture. Nils and I have read it and discussed it in depth, always wanting to translate it into a course.


## Books on Programming

- Downey, A. B. (2024). Think Python: How to think like a computer scientist (Third edition). O’Reilly. [Here](https://greenteapress.com/wp/think-python-3rd-edition/)
- Elter, S. (2021). Schrödinger programmiert Python: Das etwas andere Fachbuch (1. Auflage). Rheinwerk Verlag.

. . .

::: {.callout-note}
Think Python is a great book to start with. It's available online for free. Schrödinger Programmiert Python is a great alternative for German students, as it is a very playful introduction to programming with lots of examples.
::: 

## More Literature

For more interesting literature, take a look at the [literature list](../general/literature.qmd) of this course.

