---
title: "Lecture I - Optimal Stopping"
subtitle: "Programming: Everyday Decision-Making Algorithms"
author: "Dr. Tobias Vlćek"
format:
  revealjs:
    footer: " {{< meta title >}} | {{< meta author >}} | [Home](lec_01_optimal_stopping.qmd)"
    output-file: lec_01_presentation.html
---

# [Optimal Stopping]{.flow} {.title}

## What is Optimal Stopping?

[Question:]{.question} Anybody know what optimal stopping is?

:::{.incremental}
- [Optimal stopping]{.highlight} is the problem of:
    - choosing the **best option**
    - from a **sequence of options**
    - where the options are revealed **one by one**
:::

## {.loud-slide}
::: {.r-fit-text}
Anybody an

example of

optimal stopping?
:::

## [Flat Hunting]{.invert-font} {background-image="https://unsplash.com/photos/CAuxRJhSLC0/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8NDZ8fGhhbWJ1cmd8ZW58MHx8fHwxNzI5OTgyMjg3fDA&force=true"}
::: footer
[Photo by <a href="https://unsplash.com/@jiren_091">Aditya Ghosh</a> on Unsplash]{.invert-font}
:::

## [Hiring applicants]{.invert-font} {background-image="https://unsplash.com/photos/OQMZwNd3ThU/download?ixid=M3wxMjA3fDB8MXxhbGx8NHx8fHx8fHx8MTcyOTk3MzA0OXw&force=true"}
::: footer
[Photo by <a href="https://unsplash.com/@homajob">Scott Graham</a> on Unsplash]{.invert-font}
:::

## [Dating]{.invert-font} {background-image="https://unsplash.com/photos/-XlBjdtRqK8/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8NTV8fGxvdmV8ZW58MHx8fHwxNzI5OTI4NTkxfDA&force=true"}
::: footer
[Photo by <a href="https://unsplash.com/@shelbymary_">Shelby Deeter</a> on Unsplash]{.invert-font}
:::

## [Searching for a parking spot]{.invert-font} {background-image="https://unsplash.com/photos/FRx3dQj6iYg/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8OHx8cGFya2luZyUyMG5ldyUyMHlvcmt8ZW58MHx8fHwxNzI5OTgyNjg4fDA&force=true"}
::: footer
[Photo by <a href="https://unsplash.com/@josephtpearson">Joseph Pearson</a> on Unsplash]{.invert-font}
:::

# ["Secretary Problem"]{.flow} {.title}

## The Secretary Problem

:::{.incremental}
- Imagine you're **hiring a secretary**
- You must interview candidates **one by one**
- Now, you must decide: **hire or continue searching**
- Once you reject a candidate, **you cannot go back**
- How to [maximize chance of selecting the best candidate?]{.highlight}
:::

. . .

::: {.callout-note}
The name is a bit misleading, as the problem is not about hiring a secretary, but about finding the best candidate. It comes from the 1960s and thus a little outdated.
:::

## Basic Setup

- We have `n` candidates
- We interview them **one by one**
- We must decide to **hire or continue searching**
- [Ordinal ranking]{.highlight} of candidates

. . .

[Question:]{.question} Anybody know what ordinal ranking is?

## Ways to fail

[Question:]{.question} Anybody an idea how we can fail?

. . .

1. Reject all candidates and never hire - [stopping too late]{.highlight}
2. You hire someone too early - [stopping too early]{.highlight}

## {.loud-slide}
::: {.r-fit-text}
Ideas?
:::

## Look-and-Leap Strategy

The optimal strategy is to:

:::{.incremental}
1. Look at the [first 37 %]{.highlight} of options
2. Remember the **best one seen so far**
3. Choose the next option that's **better than the best seen**
4. Chance of selecting the best candidate is **37 %**[^1]
5. Thus, we can fail with **63 %**!
:::

[^1]: Large number of candidates! With a small number of candidates, we can do even better.

## Step-by-step Approximation

- With each additional candidate, the chance of getting a new best candidate decreases
    - 1 candidate: 100%
    - 2 candidates: 50%
    - 3 candidates: 33%
    - 4 candidates: 25%
    - 5 candidates: 20%

. . .

[Question:]{.question} Anybody see a pattern?

## Why 37%?

- This is based on the **geometric distribution**
- The [optimal stopping point]{.highlight} is at `n/e`[^8]
- `e` is the base of the natural logarithm (≈ 2.718)
- This comes from maximizing the probability of success

. . .


[^8]: This is a bit more advanced. We will not go into the details of the math here and focus more on the insights. For more details see Ferguson, T.S. (1989) ‘Who solved the secretary problem?’, Statistical Science, 4(3). doi:10.1214/ss/1177012493.

## Computing the number

```{python}
#| eval: true
#| output-location: fragment

import math

percentage = 1/math.e
print(f"Percentage of options to look at: {percentage:.3f}%")

candidates = 20
lookout_phase = candidates/math.e
print(f"Look at first {lookout_phase:.3f} candidates")
```

. . .

::: {.callout-note}
No worries if you don't understand the code! We are essentialy just using the formula to calculate the percentage of candidates to look at.
:::

## Geometric Distribution

Let's visualize the success of a simulation with 20 candidates:


```{python}
#| echo: false
#| fig-width: 7
#| fig-height: 4
import numpy as np
import matplotlib.pyplot as plt

def simulate_secretary_problem(n_candidates, stopping_position, n_trials=10000):
    successes = 0

    for _ in range(n_trials):
        # Generate random rankings
        candidates = np.random.permutation(n_candidates)
        # Best candidate seen so far
        best_so_far = float('-inf')
        # Position of the best candidate overall
        best_overall_pos = np.argmax(candidates)

        # Look at first stopping_position-1 candidates
        for i in range(stopping_position):
            if candidates[i] > best_so_far:
                best_so_far = candidates[i]

        # Try to select the best candidate after stopping position
        for i in range(stopping_position, n_candidates):
            if candidates[i] > best_so_far:
                if i == best_overall_pos:  # We found the best candidate
                    successes += 1
                break

    return successes / n_trials

# Parameters
n_candidates = 20
n_trials = 10000

# Calculate success rate for each stopping position
stopping_positions = range(1, n_candidates + 1)
success_rates = [simulate_secretary_problem(n_candidates, pos, n_trials)
                for pos in stopping_positions]

# Plotting
plt.figure(figsize=(14, 6))
plt.plot(stopping_positions, success_rates, 'b-', label='Simulated Success Rate')
plt.axvline(x=n_candidates/np.e, color='r', linestyle='--',
            label=f'Optimal stopping point (n/e ≈ {n_candidates/np.e:.0f})')

plt.xlabel('Stopping Position')
plt.ylabel('Success Rate')
plt.title(f'Secretary Problem Success Rate\n(Based on {n_trials:,} trials per position)')
plt.grid(True, alpha=0.3)
plt.legend()
plt.show()
```

# [Variations]{.flow} {.title}

## Rejection

[Question:]{.question} Imagine a dating scenario, [where the other person can also reject you]{.highlight}. **Optimal stopping point?**

:::{.incremental}
- The optimal stopping point is now **lower**
- Because we can now **fail more often**
- With 50 % chance of rejection, we **start leaping at 25 %**
- **Formula:** $q^{\frac{1}{1-q}}$ with $q$ being the chance of rejection
:::



## The role of time

What if we don't have a fixed number of candidates, but rather a [fixed amount of time]{.highlight}?

. . .

- Imagine we have **one year** to find a new flat
- We want the [best flat]{.highlight}, but don't know what a good flat is

. . .

[Question:]{.question} How should we behave?

. . .

- **Same**, but now we decide when to stop searching!

## Other versions

- Selling a house for the **best price** ("Threshold Rule")
- Stealing with a **success probability** ("Burglar's Problem")
- **Finding** a parking spot ("Parking Lot Problem") [^2]

. . .

::: {.callout-note}
Side note for drivers: An increase in occupancy from 90 to 95% doubles the search time for all drivers!
:::

# [Optimal Solution]{.flow} {.title}

## The Gambler's Fallacy

[Question:]{.question} Can you imagine a scenario where it would be unwise to use optimal stopping?

. . .

- Imagine a game with a [50 % chance of winning]{.highlight}
- If you win, your payoff is a **triple** of your bet
- If you lose, you have to pay your bet

## {.loud-slide}
::: {.r-fit-text}
Questions?
:::


## The End

::: {.callout-note}
**That's it for todays lecture!**\
We now have covered a brief introduction into optimal stopping and seen how to set up Python. Now we can start with the tutorials!
:::

# [Literature]{.flow} {.title}

## Interesting literature to start

- Christian, B., & Griffiths, T. (2016). Algorithms to live by: the computer science of human decisions. First international edition. New York, Henry Holt and Company.[^4]
- Ferguson, T.S. (1989) ‘Who solved the secretary problem?’, Statistical Science, 4(3). doi:10.1214/ss/1177012493.

[^4]: The main inspiration for this lecture. Nils and I have read it and discussed it in depth, always wanting to translate it into a course.


## Books on Programming

- Downey, A. B. (2024). Think Python: How to think like a computer scientist (Third edition). O’Reilly. [Here](https://greenteapress.com/wp/think-python-3rd-edition/)
- Elter, S. (2021). Schrödinger programmiert Python: Das etwas andere Fachbuch (1. Auflage). Rheinwerk Verlag.

. . .

::: {.callout-note}
Think Python is a great book to start with. It's available online for free. Schrödinger Programmiert Python is a great alternative for German students, as it is a very playful introduction to programming with lots of examples.
:::

## More Literature

For more interesting literature, take a look at the [literature list](../general/literature.qmd) of this course.
