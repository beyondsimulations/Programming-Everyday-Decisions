---
title: "Lecture I - Optimal Stopping"
subtitle: "Programming: Everyday Decision-Making Algorithms"
author: "Dr. Tobias Vlćek"
format:
  revealjs:
    footer: " {{< meta title >}} | {{< meta author >}} | [Home](lec_01_optimal_stopping.qmd)"
    output-file: lec_01_presentation.html
---


## Today's Topic: Optimal Stopping

**Topic:** Understanding optimal stopping problems and the famous "Secretary Problem"

**Why this matters:** Optimal stopping is everywhere in life - from hiring decisions to finding apartments to choosing when to sell stocks. Today we'll learn the mathematical strategy that maximizes your chances of making the best choice.

## Learning Objectives

By the end of this lecture, you will be able to:

:::{.incremental}
1. **Define** optimal stopping problems and identify them in real-world scenarios
2. **Apply** the 37% rule (look-and-leap strategy) to make better decisions
3. **Connect** optimal stopping principles to programming logic and algorithmic thinking
:::

## Today's Agenda

:::{.incremental}
1. **What is Optimal Stopping?** - Definition and real-world examples
2. **The Secretary Problem** - The classic formulation and solution
3. **The 37% Rule** - Why it works and how to apply it
4. **Variations & Extensions** - Rejection, time constraints, other scenarios
5. **Connecting to Programming** - How this builds our algorithmic mindset
:::

# [Optimal Stopping]{.flow} {.title}

## What is Optimal Stopping?

[Question:]{.question} Anybody know what optimal stopping is?

:::{.incremental}
- [Optimal stopping]{.highlight} is the problem of:
    - choosing the **best option**
    - from a **sequence of options**
    - where the options are revealed **one by one**
:::

## {.loud-slide}
::: {.r-fit-text}
Anybody an

example of

optimal stopping?
:::

## [Flat Hunting]{.invert-font} {background-image="https://unsplash.com/photos/CAuxRJhSLC0/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8NDZ8fGhhbWJ1cmd8ZW58MHx8fHwxNzI5OTgyMjg3fDA&force=true"}
::: footer
[Photo by <a href="https://unsplash.com/@jiren_091">Aditya Ghosh</a> on Unsplash]{.invert-font}
:::

## [Hiring applicants]{.invert-font} {background-image="https://unsplash.com/photos/OQMZwNd3ThU/download?ixid=M3wxMjA3fDB8MXxhbGx8NHx8fHx8fHx8MTcyOTk3MzA0OXw&force=true"}
::: footer
[Photo by <a href="https://unsplash.com/@homajob">Scott Graham</a> on Unsplash]{.invert-font}
:::

## [Dating]{.invert-font} {background-image="https://unsplash.com/photos/-XlBjdtRqK8/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8NTV8fGxvdmV8ZW58MHx8fHwxNzI5OTI4NTkxfDA&force=true"}
::: footer
[Photo by <a href="https://unsplash.com/@shelbymary_">Shelby Deeter</a> on Unsplash]{.invert-font}
:::

# ["Secretary Problem"]{.flow} {.title}

## The Secretary Problem

:::{.incremental}
- Imagine you're **hiring a secretary**
- You must interview candidates **one by one**
- Now, you must decide: **hire or continue searching**
- Once you reject a candidate, **you cannot go back**
- How to [maximize chance of selecting the best candidate?]{.highlight}
:::

. . .

::: {.callout-note}
The name is a bit misleading, as the problem is not about hiring a secretary, but about finding the best candidate. It comes from the 1960s and thus a little outdated.
:::

## Basic Setup

- We have `n` candidates
- We interview them **one by one**
- We must decide to **hire or continue searching**
- [Ordinal ranking]{.highlight} of candidates

. . .

[Question:]{.question} Anybody know what ordinal ranking is?

## Ways to fail

[Question:]{.question} Anybody an idea how we can fail?

. . .

1. Reject all candidates and never hire - [stopping too late]{.highlight}
2. You hire someone too early - [stopping too early]{.highlight}

## {.loud-slide}
::: {.r-fit-text}
Ideas?
:::

## Look-and-Leap Strategy

The optimal strategy is to:

:::{.incremental}
1. Look at the [first 37 %]{.highlight} of options
2. Remember the **best one seen so far**
3. Choose the next option that's **better than the best seen**
4. Chance of selecting the best candidate is **37 %**[^1]
5. Thus, we can fail with **63 %**!
:::

[^1]: Large number of candidates! With a small number of candidates, we can do even better.

## Look-and-Leap Strategy

The mathematically optimal strategy:

:::{.incremental}
1. **Look** at the [first 37%]{.highlight} of candidates without hiring anyone
2. **Remember** the best candidate from this observation phase
3. **Leap:** Hire the next candidate who is **better than the best observed**
4. **Success rate:** 37% chance of selecting the absolute best candidate
:::

[^1]: Large number of candidates! With a small number of candidates, we can do even better.
. . .

This means we fail 63% of the time - but this is the **best we can possibly do**!


## Step-by-step Approximation
Why does the success probability decrease with more candidates?

- 1 candidate: 100% (no choice!)
- 2 candidates: 50%
- 3 candidates: 33%
- 4 candidates: 25%
- 5 candidates: 20%

. . .

[Question:]{.question} Do you see the pattern?

. . .

**Pattern:** 1/n - as we have more options, each individual option is less likely to be the best.

## Why 37%?

- This is based on the **geometric distribution**
- The [optimal stopping point]{.highlight} is at `n/e`[^8]
- `e` is the base of the natural logarithm (≈ 2.718)
- This comes from maximizing the probability of success

. . .


[^8]: This is a bit more advanced. We will not go into the details of the math here and focus more on the insights. For more details see Ferguson, T.S. (1989) ‘Who solved the secretary problem?’, Statistical Science, 4(3). doi:10.1214/ss/1177012493.

## Computing the number

```{python}
#| eval: true
#| output-location: fragment

import math

percentage = 1/math.e
print(f"Percentage of options to look at: {percentage:.3f}%")

candidates = 20
lookout_phase = candidates/math.e
print(f"Look at first {lookout_phase:.3f} candidates")
```

. . .

::: {.callout-note}
No worries if you don't understand the code! We are essentialy just using the formula to calculate the percentage of candidates to look at.
:::

## Geometric Distribution

Let's visualize the success of a simulation with 20 candidates:


```{python}
#| echo: false
#| fig-width: 7
#| fig-height: 4
import numpy as np
import matplotlib.pyplot as plt

def simulate_secretary_problem(n_candidates, stopping_position, n_trials=10000):
    successes = 0

    for _ in range(n_trials):
        # Generate random rankings
        candidates = np.random.permutation(n_candidates)
        # Best candidate seen so far
        best_so_far = float('-inf')
        # Position of the best candidate overall
        best_overall_pos = np.argmax(candidates)

        # Look at first stopping_position-1 candidates
        for i in range(stopping_position):
            if candidates[i] > best_so_far:
                best_so_far = candidates[i]

        # Try to select the best candidate after stopping position
        for i in range(stopping_position, n_candidates):
            if candidates[i] > best_so_far:
                if i == best_overall_pos:  # We found the best candidate
                    successes += 1
                break

    return successes / n_trials

# Parameters
n_candidates = 20
n_trials = 10000

# Calculate success rate for each stopping position
stopping_positions = range(1, n_candidates + 1)
success_rates = [simulate_secretary_problem(n_candidates, pos, n_trials)
                for pos in stopping_positions]

# Plotting
plt.figure(figsize=(14, 6))
plt.plot(stopping_positions, success_rates, 'b-', label='Simulated Success Rate')
plt.axvline(x=n_candidates/np.e, color='r', linestyle='--',
            label=f'Optimal stopping point (n/e ≈ {n_candidates/np.e:.0f})')

plt.xlabel('Stopping Position')
plt.ylabel('Success Rate')
plt.title(f'Secretary Problem Success Rate\n(Based on {n_trials:,} trials per position)')
plt.grid(True, alpha=0.3)
plt.legend()
plt.show()
```

# [Variations]{.flow} {.title}

## Rejection

[Question:]{.question} Imagine a dating scenario, [where the other person can also reject you]{.highlight}. **Optimal stopping point?**

:::{.incremental}
- The optimal stopping point is now **lower**
- Because we can now **fail more often**
- With 50 % chance of rejection, we **start leaping at 25 %**
- **Formula:** $q^{\frac{1}{1-q}}$ with $q$ being the chance of rejection
:::

## Mutual Rejection

[Question:]{.question} What if in dating, [the other person can also reject you]{.highlight}?

:::{.incremental}
- The optimal stopping point **decreases**
- We need to account for rejection risk
- With 50% rejection probability: **start accepting at 25%**
- **Formula:** $q^{\frac{1}{1-q}}$ where $q$ = rejection probability
:::

. . .

**Life lesson:** Higher risk of rejection means we should be less picky!

## Time Constraints

What if we don't have a fixed number of candidates, but a [fixed amount of time]{.highlight}?

. . .

**Example:** One year to find an apartment

. . .

[Question:]{.question} How should we adapt our strategy?

. . .

:::{.incremental}
- **Same principle applies!** Observe for first 37% of available time
- But now we also control the **search intensity**
- This connects to **resource allocation** problems in computer science
:::

## Other versions

- Selling a house for the **best price** ("Threshold Rule")
- Stealing with a **success probability** ("Burglar's Problem")
- **Finding** a parking spot ("Parking Lot Problem") [^2]

. . .

::: {.callout-note}
Side note for drivers: An increase in occupancy from 90 to 95% doubles the search time for all drivers!
:::

## Building Your Technical Mindset

[Question:]{.question} **How does optimal stopping connect to programming?**

. . .

:::{.incremental}
1. **Algorithmic thinking:** Break complex decisions into logical steps
2. **Trade-off analysis:** Exploration vs. exploitation (fundamental in AI)
3. **Mathematical optimization:** Using formulas to find best solutions
:::

## Key Takeaways

**What we learned:**

:::{.incremental}
1. **Optimal stopping problems** are everywhere in life and business
2. **The 37% rule** provides a mathematically optimal strategy
3. **Exploration vs. exploitation** is a fundamental trade-off
4. **Real-world variations** require adapting the basic strategy
5. **This thinking** builds foundation for algorithmic problem-solving
:::


## The End

::: {.callout-note}
**That's it for todays lecture!**\
We now have covered a brief introduction into optimal stopping and seen how to set up Python. Now we can start with the tutorials!
:::

# [Literature]{.flow} {.title}

## Interesting literature to start

- Christian, B., & Griffiths, T. (2016). Algorithms to live by: the computer science of human decisions. First international edition. New York, Henry Holt and Company.[^4]
- Ferguson, T.S. (1989) ‘Who solved the secretary problem?’, Statistical Science, 4(3). doi:10.1214/ss/1177012493.

[^4]: The main inspiration for this lecture. Nils and I have read it and discussed it in depth, always wanting to translate it into a course.


## Books on Programming

- Downey, A. B. (2024). Think Python: How to think like a computer scientist (Third edition). O’Reilly. [Here](https://greenteapress.com/wp/think-python-3rd-edition/)
- Elter, S. (2021). Schrödinger programmiert Python: Das etwas andere Fachbuch (1. Auflage). Rheinwerk Verlag.

. . .

::: {.callout-note}
Think Python is a great book to start with. It's available online for free. Schrödinger Programmiert Python is a great alternative for German students, as it is a very playful introduction to programming with lots of examples.
:::

## More Literature

For more interesting literature, take a look at the [literature list](../general/literature.qmd) of this course.
